{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:51:44.437555200Z",
     "start_time": "2023-11-07T09:51:44.437041600Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "from transformers.optimization import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:51:44.444046Z",
     "start_time": "2023-11-07T09:51:44.437555200Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:51:44.450555800Z",
     "start_time": "2023-11-07T09:51:44.444046Z"
    }
   },
   "outputs": [],
   "source": [
    "# set dimension of interest\n",
    "# dim = 'romance'\n",
    "dims = [\n",
    "        'social_support',\n",
    "        'conflict',\n",
    "        'trust',\n",
    "        'fun',\n",
    "        'similarity',\n",
    "        'identity',\n",
    "        'respect',\n",
    "        'romance',\n",
    "        'knowledge',\n",
    "        'power'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:51:44.456967900Z",
     "start_time": "2023-11-07T09:51:44.452559100Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = 'data/%s'%dim # directory of where the train/test/dev files are stored\n",
    "# OUTPUT_DIR = 'weights/BERT/%s' %dim # where the model weights will be stored\n",
    "BERT_MODEL = 'bert-base-cased' # BERT model type\n",
    "CACHE_DIR = 'cache/' # where BERT will look for pre-trained models to load parameters from\n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "OUTPUT_MODE = 'classification'\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:51:45.324874100Z",
     "start_time": "2023-11-07T09:51:44.458970200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL,cache_dir=CACHE_DIR, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T09:58:03.414708700Z",
     "start_time": "2023-11-07T09:57:12.620287800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: Well... listen, if you need any help, you know, back up, call me, OK?\n",
      "\tsocial_support:\t0.927\n",
      "\tconflict:\t0.008\n",
      "\ttrust:\t0.026\n",
      "\tfun:\t0.024\n",
      "\tsimilarity:\t0.038\n",
      "\tidentity:\t0.003\n",
      "\trespect:\t0.009\n",
      "\tromance:\t0.000\n",
      "\tknowledge:\t0.003\n",
      "\tpower:\t0.011\n",
      "\n",
      "2: Forgive me for askin', son, and I don't mean to belabor the obvious, but why is it that you've got your head so far up your own ass?\n",
      "\tsocial_support:\t0.078\n",
      "\tconflict:\t0.970\n",
      "\ttrust:\t0.026\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.031\n",
      "\tidentity:\t0.003\n",
      "\trespect:\t0.168\n",
      "\tromance:\t0.000\n",
      "\tknowledge:\t0.003\n",
      "\tpower:\t0.011\n",
      "\n",
      "3: I'm trying to tell you - and this is where you have to trust me - but, I think your life might be in real danger\n",
      "\tsocial_support:\t0.535\n",
      "\tconflict:\t0.046\n",
      "\ttrust:\t0.309\n",
      "\tfun:\t0.024\n",
      "\tsimilarity:\t0.012\n",
      "\tidentity:\t0.003\n",
      "\trespect:\t0.002\n",
      "\tromance:\t0.001\n",
      "\tknowledge:\t0.006\n",
      "\tpower:\t0.011\n",
      "\n",
      "4: It's just funny...who needs a serial psycho in the woods with a chainsaw when we have ourselves\n",
      "\tsocial_support:\t0.002\n",
      "\tconflict:\t0.978\n",
      "\ttrust:\t0.027\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.009\n",
      "\tidentity:\t0.004\n",
      "\trespect:\t0.002\n",
      "\tromance:\t0.001\n",
      "\tknowledge:\t0.027\n",
      "\tpower:\t0.011\n",
      "\n",
      "5: My friends used to live in a large city in Asia too\n",
      "\tsocial_support:\t0.047\n",
      "\tconflict:\t0.007\n",
      "\ttrust:\t0.028\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.755\n",
      "\tidentity:\t0.004\n",
      "\trespect:\t0.004\n",
      "\tromance:\t0.001\n",
      "\tknowledge:\t0.128\n",
      "\tpower:\t0.011\n",
      "\n",
      "6: Hey, I know what I'm talkin' about, black women ain't the same as white women\n",
      "\tsocial_support:\t0.003\n",
      "\tconflict:\t0.984\n",
      "\ttrust:\t0.026\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.276\n",
      "\tidentity:\t0.004\n",
      "\trespect:\t0.004\n",
      "\tromance:\t0.000\n",
      "\tknowledge:\t0.099\n",
      "\tpower:\t0.011\n",
      "\n",
      "7: Frankie, you're a good old man, and you've been loyal to my Father for years...so I hope you can explain what you mean\n",
      "\tsocial_support:\t0.821\n",
      "\tconflict:\t0.015\n",
      "\ttrust:\t0.027\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.030\n",
      "\tidentity:\t0.003\n",
      "\trespect:\t0.028\n",
      "\tromance:\t0.001\n",
      "\tknowledge:\t0.003\n",
      "\tpower:\t0.011\n",
      "\n",
      "8: I'm going to marry the woman I love\n",
      "\tsocial_support:\t0.013\n",
      "\tconflict:\t0.004\n",
      "\ttrust:\t0.026\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.011\n",
      "\tidentity:\t0.005\n",
      "\trespect:\t0.004\n",
      "\tromance:\t0.983\n",
      "\tknowledge:\t0.002\n",
      "\tpower:\t0.011\n",
      "\n",
      "9: Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you end your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil\n",
      "\tsocial_support:\t0.009\n",
      "\tconflict:\t0.054\n",
      "\ttrust:\t0.029\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.013\n",
      "\tidentity:\t0.024\n",
      "\trespect:\t0.002\n",
      "\tromance:\t0.001\n",
      "\tknowledge:\t0.892\n",
      "\tpower:\t0.011\n",
      "\n",
      "10: Right now you're in no position to ask questions! And your snide remarks...\n",
      "\tsocial_support:\t0.016\n",
      "\tconflict:\t0.990\n",
      "\ttrust:\t0.025\n",
      "\tfun:\t0.025\n",
      "\tsimilarity:\t0.002\n",
      "\tidentity:\t0.003\n",
      "\trespect:\t0.002\n",
      "\tromance:\t0.000\n",
      "\tknowledge:\t0.004\n",
      "\tpower:\t0.011\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "## load sentences\n",
    "file = open('C:\\\\Users\\\\fonta\\\\PycharmProjects\\\\10_dimensions_classifier\\\\data\\\\examples.txt')\n",
    "examples = json.load(file)\n",
    "scoring = {}\n",
    "for id in examples:\n",
    "    sentence = examples[id]\n",
    "    scoring.update({sentence: {}})\n",
    "    print(f'\\n{id}: {sentence}')\n",
    "    for dim in dims:\n",
    "        DATA_DIR = 'data/%s'%dim\n",
    "        OUTPUT_DIR = 'weights/BERT/%s' %dim\n",
    "        # load pretrained BERT model for specific dimension\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
    "        model.load_state_dict(torch.load(output_model_file))\n",
    "        model.to(device)\n",
    "        tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)\n",
    "\n",
    "        input_ids = torch.tensor([tokenizer.encode(sentence,add_special_tokens=True)]).cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)[0]\n",
    "            score = torch.softmax(outputs,1)\n",
    "        scoring[sentence].update({dim: round(score[0,1].item(), 3)})\n",
    "        print(\"\\t%s:\\t%1.3f\" % (dim,score[0,1].item()))\n",
    "\n",
    "with open('C:\\\\Users\\\\fonta\\\\PycharmProjects\\\\10_dimensions_classifier\\\\out\\\\examples_scoring.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(scoring))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
