{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from features import ExtractWordEmbeddings\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from models.lstm import LSTMClassifier\n",
    "tokenize = TweetTokenizer().tokenize\n",
    "from preprocess_data import padBatch\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\" # change GPU number depending on your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a dimension based on these 10 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [\n",
    "        'social_support',\n",
    "        'conflict',\n",
    "        'trust',\n",
    "        'fun',\n",
    "        'similarity',\n",
    "        'identity',\n",
    "        'respect',\n",
    "        'romance',\n",
    "        'knowledge',\n",
    "        'power'\n",
    "        ]\n",
    "\n",
    "dim = 'INSERT DIMENSION HERE'\n",
    "dim = 'conflict'\n",
    "is_cuda = False # set to true only when using a GPU\n",
    "\n",
    "weight_file = 'weights/LSTM/%s/best-weights.pth'%dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "em = ExtractWordEmbeddings(emb_type='glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = LSTMClassifier(embedding_dim=300, hidden_dim=300)\n",
    "state_dict = torch.load(weight_file)\n",
    "model.load_state_dict(state_dict)\n",
    "if is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert random sentences to obtain probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84 baha'i faith makes sense once you accept it as openly hypocritical.\n",
      "0.5 your opinion strongly contrasts with mine\n",
      "0.61 i do not believe in your words\n",
      "0.41 i trust you\n",
      "0.46 i believe in you\n",
      "0.52 believe me, that is not going to work\n",
      "0.19 i love you so much\n",
      "0.65 i hate you\n",
      "0.47 I don't love you any more\n",
      "0.35 i am proud of you\n",
      "0.52 i agree with that guy\n",
      "0.18 Thank you so much\n",
      "0.33 good to hear from you\n",
      "0.39 this is exactly what i wanted\n",
      "0.5 this is not what i wanted\n",
      "0.89 get off, you are wrong i do not want any more of this conversation\n",
      "0.56 oh this is too bad\n"
     ]
    }
   ],
   "source": [
    "sents = [\n",
    "    \"baha'i faith makes sense once you accept it as openly hypocritical.\",\n",
    "    'your opinion strongly contrasts with mine',\n",
    "    'i do not believe in your words',\n",
    "    'i trust you',\n",
    "    'i believe in you',\n",
    "    'believe me, that is not going to work',\n",
    "    'i love you so much',\n",
    "    'i hate you',\n",
    "    \"I don't love you any more\",\n",
    "    'i am proud of you',\n",
    "    'i agree with that guy',\n",
    "    'Thank you so much',\n",
    "    'good to hear from you',\n",
    "    'this is exactly what i wanted',\n",
    "    'this is not what i wanted',\n",
    "    'get off, you are wrong i do not want any more of this conversation',\n",
    "    'oh this is too bad'\n",
    "]\n",
    "vector = torch.tensor(padBatch([em.obtain_vectors_from_sentence(tokenize(sent),True) for sent in sents])).float()\n",
    "scores = model(vector)\n",
    "for i in range(len(sents)):\n",
    "    print(round(scores[i].item(),2),sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
