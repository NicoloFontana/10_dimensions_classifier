{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T17:27:56.963906Z",
     "start_time": "2023-11-06T17:27:56.945844500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from features import ExtractWordEmbeddings\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from models.lstm import LSTMClassifier\n",
    "tokenize = TweetTokenizer().tokenize\n",
    "from preprocess_data import padBatch\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\" # change GPU number depending on your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a dimension based on these 10 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T17:27:56.970919800Z",
     "start_time": "2023-11-06T17:27:56.950927200Z"
    }
   },
   "outputs": [],
   "source": [
    "dims = [\n",
    "        'social_support',\n",
    "        'conflict',\n",
    "        'trust',\n",
    "        'fun',\n",
    "        'similarity',\n",
    "        'identity',\n",
    "        'respect',\n",
    "        'romance',\n",
    "        'knowledge',\n",
    "        'power'\n",
    "        ]\n",
    "\n",
    "dim = 'INSERT DIMENSION HERE'\n",
    "dim = 'conflict'\n",
    "is_cuda = False # set to true only when using a GPU\n",
    "\n",
    "weight_file = 'weights\\\\LSTM\\\\%s\\\\best-weights.pth'%dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T17:27:57.014612100Z",
     "start_time": "2023-11-06T17:27:56.956571400Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights/embeddings\\\\glove.840B.300d.wv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# load embeddings\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m em \u001B[38;5;241m=\u001B[39m ExtractWordEmbeddings(emb_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mglove\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\10_dimensions_classifier\\features.py:67\u001B[0m, in \u001B[0;36mExtractWordEmbeddings.__init__\u001B[1;34m(self, emb_type, emb_dir, method)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m emb_type\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mglove\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;66;03m# load_dir = join(emb_dir,'glove/glove.twitter.27B.200d.wv')\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     load_dir \u001B[38;5;241m=\u001B[39m join(emb_dir,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mglove.840B.300d.wv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m KeyedVectors\u001B[38;5;241m.\u001B[39mload(load_dir,mmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb_type \u001B[38;5;241m=\u001B[39m emb_type\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod \u001B[38;5;241m=\u001B[39m method\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cuda_20231105\\Lib\\site-packages\\gensim\\utils.py:486\u001B[0m, in \u001B[0;36mSaveLoad.load\u001B[1;34m(cls, fname, mmap)\u001B[0m\n\u001B[0;32m    482\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m object from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, fname)\n\u001B[0;32m    484\u001B[0m compress, subname \u001B[38;5;241m=\u001B[39m SaveLoad\u001B[38;5;241m.\u001B[39m_adapt_by_suffix(fname)\n\u001B[1;32m--> 486\u001B[0m obj \u001B[38;5;241m=\u001B[39m unpickle(fname)\n\u001B[0;32m    487\u001B[0m obj\u001B[38;5;241m.\u001B[39m_load_specials(fname, mmap, compress, subname)\n\u001B[0;32m    488\u001B[0m obj\u001B[38;5;241m.\u001B[39madd_lifecycle_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m, fname\u001B[38;5;241m=\u001B[39mfname)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cuda_20231105\\Lib\\site-packages\\gensim\\utils.py:1460\u001B[0m, in \u001B[0;36munpickle\u001B[1;34m(fname)\u001B[0m\n\u001B[0;32m   1446\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munpickle\u001B[39m(fname):\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001B[39;00m\n\u001B[0;32m   1448\u001B[0m \n\u001B[0;32m   1449\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1458\u001B[0m \n\u001B[0;32m   1459\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1460\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(fname, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m   1461\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _pickle\u001B[38;5;241m.\u001B[39mload(f, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cuda_20231105\\Lib\\site-packages\\smart_open\\smart_open_lib.py:188\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transport_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    186\u001B[0m     transport_params \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 188\u001B[0m fobj \u001B[38;5;241m=\u001B[39m _shortcut_open(\n\u001B[0;32m    189\u001B[0m     uri,\n\u001B[0;32m    190\u001B[0m     mode,\n\u001B[0;32m    191\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[0;32m    192\u001B[0m     buffering\u001B[38;5;241m=\u001B[39mbuffering,\n\u001B[0;32m    193\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m    194\u001B[0m     errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    195\u001B[0m     newline\u001B[38;5;241m=\u001B[39mnewline,\n\u001B[0;32m    196\u001B[0m )\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fobj\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cuda_20231105\\Lib\\site-packages\\smart_open\\smart_open_lib.py:361\u001B[0m, in \u001B[0;36m_shortcut_open\u001B[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    359\u001B[0m     open_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merrors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m errors\n\u001B[1;32m--> 361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _builtin_open(local_path, mode, buffering\u001B[38;5;241m=\u001B[39mbuffering, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopen_kwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'weights/embeddings\\\\glove.840B.300d.wv'"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "em = ExtractWordEmbeddings(emb_type='glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T17:27:57.013467300Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = LSTMClassifier(embedding_dim=300, hidden_dim=300)\n",
    "state_dict = torch.load(weight_file)\n",
    "model.load_state_dict(state_dict)\n",
    "if is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert random sentences to obtain probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"baha'i faith makes sense once you accept it as openly hypocritical.\",\n",
    "    'your opinion strongly contrasts with mine',\n",
    "    'i do not believe in your words',\n",
    "    'i trust you',\n",
    "    'i believe in you',\n",
    "    'believe me, that is not going to work',\n",
    "    'i love you so much',\n",
    "    'i hate you',\n",
    "    \"I don't love you any more\",\n",
    "    'i am proud of you',\n",
    "    'i agree with that guy',\n",
    "    'Thank you so much',\n",
    "    'good to hear from you',\n",
    "    'this is exactly what i wanted',\n",
    "    'this is not what i wanted',\n",
    "    'get off, you are wrong i do not want any more of this conversation',\n",
    "    'oh this is too bad'\n",
    "]\n",
    "vector = torch.tensor(padBatch([em.obtain_vectors_from_sentence(tokenize(sent),True) for sent in sents])).float()\n",
    "scores = model(vector)\n",
    "for i in range(len(sents)):\n",
    "    print(round(scores[i].item(),2),sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
